{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation Notebook\n",
    "## Summary\n",
    "In this notebook, I imported all of the data wrangling functions produced in the previous Analysis notebook and used them to more efficiently load and clean datasets for 2016 and 2017 data. I then trained the LGBM and Random Forest models on 2016 data, before validating individual and ensemble results on unseen 2017 data from Q1 and Q2—the most recent data available. I selected the best performing model on the validation set, and then used it to create a final test-set accuracy metric.\n",
    "\n",
    "## Results\n",
    "The accuray metrics for the LGBM, Random Forest, and LGBM+Random Forest on the 2017 validation set were:\n",
    "- LGBM: 0.659\n",
    "- Random Forest: 0.648\n",
    "- LGBM+RF Ensemble: 0.659\n",
    "\n",
    "Based on the above results, I chose the LGBM model due to its higher accuracy compared to Random Forest and its speed over the LGBM+RF Ensemble.\n",
    "\n",
    "The final test prediction accuracy for the LGBM on 2017 test set was 65.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved functions from other notebook\n",
    "from data_wrangle_functions import *\n",
    "\n",
    "# general use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.mode.chained_assignment = None\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from my_plot import PrettyPlot\n",
    "PrettyPlot(plt);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Wrangling Functions\n",
    "The functions below combine all of the data cleaning and feature engineering steps that I discussed in the Analysis notebook. The workflow consists of:\n",
    "1. Loading trips data and merging with stations data already containing the cluster information.\n",
    "2. Adding the target data using Great Circle and Google Maps.\n",
    "3. Removing unnecessary columns, imputing missing values, and formatting datetime series.\n",
    "4. Adding information about hourly temperature.\n",
    "5. Converting the date and time information to cyclical.\n",
    "\n",
    "These general functions will be used to import and format the 2016 training data and 2017 validation / testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(stations, path):\n",
    "    \n",
    "    trips = data_load(path)\n",
    "    trips, _ = trips_station_merge(trips, stations)\n",
    "    \n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_target(trips, max_dist, min_dist, n_samples, targets_inst, fit=True):\n",
    "    \n",
    "    trips = great_circle_calc(trips)\n",
    "    \n",
    "    if fit == True:\n",
    "        distances_df = gmaps_distance(trips, max_dist=max_dist, min_dist=min_dist, samples=n_samples)\n",
    "        targets_inst, _ = target_creation(distances_df).fit()\n",
    "        targets_inst.transform(trips);\n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    return trips, targets_inst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_format(trips, col_to_drop, date_format, is_2016=False):\n",
    "    \n",
    "    trips = feature_cleaning(trips, col_to_drop)\n",
    "    \n",
    "    if is_2016 == True:\n",
    "        trips = fix_2016(trips)\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    format_date_inst = format_dates(trips, date_formats=date_format)\n",
    "    format_date_inst.add_holidays(trips)\n",
    "    format_date_inst.create_day_week_hour(trips, date_formats=['%Y-%M-%D %H:%M:%S', '%m/%d/%Y'])\n",
    "    format_date_inst.specify_weekend(trips);\n",
    "    \n",
    "    trips = column_rename(trips)\n",
    "    \n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weather(trips, start_date, end_date):\n",
    "    \n",
    "    weather_data = obtain_weather(date_start=start_date, date_end=end_date)\n",
    "    trips = add_weather_feature(trips, weather_data)\n",
    "    \n",
    "    return trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_cycles(trips):\n",
    "    \n",
    "    ct = convert_time(trips)\n",
    "    \n",
    "    ct.cyclical_hour(trips)\n",
    "    ct.cyclical_month(trips)\n",
    "    ct.cyclical_day(trips)\n",
    "    ct.cyclical_day_of_week(trips)\n",
    "    \n",
    "    return trips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 2016 Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2016 = data_loading(stations, 'trips2016/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2016, targets_inst = add_target(trips_2016, max_dist=2.5, min_dist=1.0,\n",
    "                                     n_samples=2000, targets_inst=None, fit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_drop = ['bikeid', 'stoptime', 'tripduration', 'from_station_name', \n",
    "            'to_station_id', 'to_station_name', 'id_end', 'id_start', 'cluster_end', \n",
    "            'latitude_start', 'longitude_start', 'latitude_end', 'longitude_end', \n",
    "            'dpcapacity_end', 'online_date_end', 'circle_dist', 'gmaps_dist']\n",
    "\n",
    "\n",
    "date_formats = ['%Y-%M-%D %H:%M:%S', '%m/%d/%Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2016 = clean_and_format(trips_2016, col_drop, date_format=date_formats, is_2016=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2016 = add_weather(trips_2016, start_date='201601', end_date='201701')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2016 = time_cycles(trips_2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_cols = ['usertype', 'gender', 'cluster_start']\n",
    "\n",
    "trips_2016 = trips_2016.dropna()\n",
    "X_2016 = one_hot_encode(trips_2016, dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 3594737 , #features: 121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>dpcapacity_start</th>\n",
       "      <th>holiday</th>\n",
       "      <th>station_age</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>temperature</th>\n",
       "      <th>start_hour_sin</th>\n",
       "      <th>start_hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_90</th>\n",
       "      <th>cluster_91</th>\n",
       "      <th>cluster_92</th>\n",
       "      <th>cluster_93</th>\n",
       "      <th>cluster_94</th>\n",
       "      <th>cluster_95</th>\n",
       "      <th>cluster_96</th>\n",
       "      <th>cluster_97</th>\n",
       "      <th>cluster_98</th>\n",
       "      <th>cluster_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8547211</td>\n",
       "      <td>1965.0</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>260</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8547214</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8547215</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>828</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8547216</td>\n",
       "      <td>1982.0</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8547217</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>15</td>\n",
       "      <td>True</td>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trip_id  birthyear  dpcapacity_start  holiday  station_age is_weekend  \\\n",
       "0  8547211     1965.0                15     True          260          0   \n",
       "1  8547214     1981.0                15     True          878          0   \n",
       "2  8547215     1994.0                15     True          828          0   \n",
       "3  8547216     1982.0                15     True          238          0   \n",
       "4  8547217     1976.0                15     True          238          0   \n",
       "\n",
       "   temperature  start_hour_sin  start_hour_cos  month_sin     ...      \\\n",
       "0         25.0             0.0             1.0        0.0     ...       \n",
       "1         25.0             0.0             1.0        0.0     ...       \n",
       "2         25.0             0.0             1.0        0.0     ...       \n",
       "3         25.0             0.0             1.0        0.0     ...       \n",
       "4         25.0             0.0             1.0        0.0     ...       \n",
       "\n",
       "   cluster_90  cluster_91  cluster_92  cluster_93  cluster_94  cluster_95  \\\n",
       "0           0           0           0           0           0           0   \n",
       "1           0           0           0           0           0           0   \n",
       "2           0           0           0           0           0           0   \n",
       "3           0           0           0           0           0           0   \n",
       "4           0           0           0           0           0           0   \n",
       "\n",
       "   cluster_96  cluster_97  cluster_98  cluster_99  \n",
       "0           0           0           0           0  \n",
       "1           0           0           0           0  \n",
       "2           0           0           0           0  \n",
       "3           0           0           0           0  \n",
       "4           0           0           0           0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2016 = trips_2016.shorter_two\n",
    "df_info(X_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 2017 Validate and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2017 = data_loading(stations, 'trips2017/')\n",
    "trips_2017 = trips_2017.rename(columns={'end_time': 'stoptime'})\n",
    "trips_2017 = trips_2017.dropna(subset=['cluster_start', 'cluster_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2017, _ = add_target(trips_2017, max_dist=2.5, min_dist=1.0,\n",
    "                       n_samples=2000, targets_inst=targets_inst, fit=False)\n",
    "\n",
    "targets_inst.transform(trips_2017);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_formats = ['%m/%d/%Y %H:%M:%S', '%m/%d/%Y']\n",
    "\n",
    "trips_2017 = clean_and_format(trips_2017, col_drop, date_format=date_formats, is_2016=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2017['start_time'] = pd.to_datetime(trips_2017.start_time, format='%m/%d/%Y %H:%M:%S')\n",
    "trips_2017 = add_weather(trips_2017, start_date='201701', end_date='201707')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2017 = time_cycles(trips_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_2017 = trips_2017.dropna()\n",
    "X_2017 = one_hot_encode(trips_2017, dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#samples: 1547163 , #features: 121\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>birthyear</th>\n",
       "      <th>dpcapacity_start</th>\n",
       "      <th>holiday</th>\n",
       "      <th>station_age</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>temperature</th>\n",
       "      <th>start_hour_sin</th>\n",
       "      <th>start_hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>...</th>\n",
       "      <th>cluster_90.0</th>\n",
       "      <th>cluster_91.0</th>\n",
       "      <th>cluster_92.0</th>\n",
       "      <th>cluster_93.0</th>\n",
       "      <th>cluster_94.0</th>\n",
       "      <th>cluster_95.0</th>\n",
       "      <th>cluster_96.0</th>\n",
       "      <th>cluster_97.0</th>\n",
       "      <th>cluster_98.0</th>\n",
       "      <th>cluster_99.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12979230</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>403</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12979231</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1289</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12979232</td>\n",
       "      <td>1985.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>True</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12979233</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1206</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12979234</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>True</td>\n",
       "      <td>1200</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    trip_id  birthyear  dpcapacity_start  holiday  station_age is_weekend  \\\n",
       "0  12979230     1984.0              15.0     True          403          1   \n",
       "1  12979231     1984.0              15.0     True         1289          1   \n",
       "2  12979232     1985.0              15.0     True          114          1   \n",
       "3  12979233     1990.0              27.0     True         1206          1   \n",
       "4  12979234     1990.0              19.0     True         1200          1   \n",
       "\n",
       "   temperature  start_hour_sin  start_hour_cos  month_sin      ...       \\\n",
       "0         25.0             0.0             1.0        0.0      ...        \n",
       "1         25.0             0.0             1.0        0.0      ...        \n",
       "2         25.0             0.0             1.0        0.0      ...        \n",
       "3         25.0             0.0             1.0        0.0      ...        \n",
       "4         25.0             0.0             1.0        0.0      ...        \n",
       "\n",
       "   cluster_90.0  cluster_91.0  cluster_92.0  cluster_93.0  cluster_94.0  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   cluster_95.0  cluster_96.0  cluster_97.0  cluster_98.0  cluster_99.0  \n",
       "0             0             0             0             0             0  \n",
       "1             0             0             0             0             0  \n",
       "2             0             0             0             0             0  \n",
       "3             0             0             0             0             0  \n",
       "4             0             0             0             0             0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_2017 = trips_2017.shorter_two\n",
    "df_info(X_2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. LightGBM and Random Forest Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, I trained the LGBM and Random Forest models on the entire 2016 dataset. I used the best parameters found for the LGBM model (n_estimators=2000, learning_rate=0.125), but slightly reduced the number of estimators in the Random Forest model to improve generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', colsample_bytree=1.0,\n",
       "        learning_rate=0.125, max_bin=255, max_depth=-1,\n",
       "        min_child_samples=10, min_child_weight=5, min_split_gain=0.0,\n",
       "        n_estimators=2000, n_jobs=-1, num_leaves=31, objective=None,\n",
       "        random_state=0, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=50000, subsample_freq=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=2000, learning_rate=0.125)\n",
    "lgbm.fit(X_2016, y_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=300)\n",
    "rf.fit(X_2016, y_2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Validation and Testing on 2017 data\n",
    "In this section, I evaluated my models on the most current 2017 data to ensure that they will provide reasonable accuracy on unseen data for future-looking predictions. I created a validation set to choose between using the LGBM only, Random Forest only, or an ensemble average between the two for the final model selection. The best performing model is then evaluated on the final 2017 test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Creating equal-sized validation and test sets for 2017 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_validate, X_test, y_validate, y_test = train_test_split(X_2017, y_2017, \n",
    "                                                          test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Evaluating LGBM only, RF only, and Ensemble on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Validation Accuracy: 0.659\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predict_lgbm = lgbm.predict(X_validate)\n",
    "print('LGBM Validation Accuracy:',\n",
    "      round(accuracy_score(predict_lgbm, y_validate), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Validation Accuracy: 0.648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "predict_rf = rf.predict(X_validate)\n",
    "print('Random Forest Validation Accuracy:',\n",
    "      round(accuracy_score(predict_rf, y_validate), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ensemble average function below calculates the prediction probability and then averages the probabilities before being converted to the binary prediction. I chose this method because I only had two models with high enough accuracy to consider for the ensemble. I tried to add the logistic regression model and use a majority-vote ensemble method, but the lower accuracy of the logistic regression model seemed to reduce accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_average(X_to_predict, models):\n",
    "    \n",
    "    results = []\n",
    "    for model in models:\n",
    "\n",
    "        proba = model.predict_proba(X_to_predict)\n",
    "        results.append(proba[:,0])\n",
    "    \n",
    "    avg_proba = np.mean([results[1], results[0]], axis=0)\n",
    "    predictions = np.where(avg_proba > 0.5, 0, 1)\n",
    "    \n",
    "    return avg_proba, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [lgbm, rf]\n",
    "avg_proba, predictions = ensemble_average(X_validate, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Validation Accuracy: 0.659\n"
     ]
    }
   ],
   "source": [
    "print('Ensemble Validation Accuracy:',\n",
    "      round(accuracy_score(predictions, y_validate), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Final Test Set Accuracy\n",
    "Because the LGBM model gives the highest accuracy out of the 3 evaluated validation models, I decided to move forward with it alone. It also has the benefit of being signficantly faster than other tested models. The final accuracy score on the 2017 test data is shown below as 65.9%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBM Test Accuracy: 0.659\n"
     ]
    }
   ],
   "source": [
    "predict_lgbm = lgbm.predict(X_test)\n",
    "print('LGBM Test Accuracy:',\n",
    "      round(accuracy_score(predict_lgbm, y_test), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Final Thoughts\n",
    "Interestingly, the Random Forest model went from having the highest prediction accuracy on the cross-validated 2016 dataset in the previous notebook (~68% compared to 67%), to having slightly less accuracy than the LGBM model on unseen 2017 data. Given more time / computing resources, it would be beneficial to explore learning curves for the Random Forest model and use those results to guide hyperparameter optimization. \n",
    "\n",
    "Further, I think that trying to obtain an additional (or three) models that perform on-par with these two would be useful for creating a majority vote ensemble, or using a stacker to better improve individual model performance. That being said, the LGBM provides reasonable accuracy for this problem, while also excelling in terms of speed and computing cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
